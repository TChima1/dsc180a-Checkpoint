# -*- coding: utf-8 -*-
"""week3_pubmed_repurposing.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ymrh0Bge_bce2-Xnedf2IhFMHwgRgVCi
"""

"""
Week 3: Drug Repurposing via PubMed Literature Mining
"""

import os
import pandas as pd
import asyncio
from Bio import Entrez
from semlib import Session
from collections import Counter

API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("Please set OPENAI_API_KEY environment variable")

os.environ["OPENAI_API_KEY"] = API_KEY

session = Session(model="openai/gpt-4o-mini", max_concurrency=3)
Entrez.email = "youremail@ucsd.edu"

def fetch_pubmed_abstracts(query, max_results=50):

    print(f"Searching PubMed: {query}")

    handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results)
    record = Entrez.read(handle)
    handle.close()
    pmids = record["IdList"]

    print(f"Found {len(pmids)} articles")

    handle = Entrez.efetch(db="pubmed", id=pmids, rettype="abstract", retmode="xml")
    records = Entrez.read(handle)
    handle.close()

    abstracts = []
    for article in records['PubmedArticle']:
        try:
            pmid = str(article['MedlineCitation']['PMID'])
            title = article['MedlineCitation']['Article']['ArticleTitle']
            abstract_texts = article['MedlineCitation']['Article'].get('Abstract', {}).get('AbstractText', [])
            abstract = ' '.join([str(text) for text in abstract_texts])
            year = article['MedlineCitation']['Article']['Journal']['JournalIssue'].get('PubDate', {}).get('Year', 'N/A')

            abstracts.append({
                'pmid': pmid,
                'title': title,
                'abstract': abstract,
                'year': year
            })
        except Exception:
            continue

    return pd.DataFrame(abstracts)

async def extract_drug_candidates(df):

    print(f"\nExtracting candidates from {len(df)} abstracts using semlib")
    print(f"Model: {session.model}\n")

    abstracts = df['abstract'].tolist()

    results = await session.map(
        abstracts,
        template=lambda abstract: f"""
        Extract drug repurposing candidates from this abstract.
        List only drug names, separated by commas.
        If no drugs mentioned, respond with "none".

        Abstract: {abstract}
        """.strip()
    )

    return results

async def main():

    query = '("Alzheimer disease"[MeSH Terms]) AND ("drug repositioning"[MeSH Terms] OR "drug repurposing"[Title/Abstract])'

    df = fetch_pubmed_abstracts(query, max_results=50)
    df.to_csv('drug_repurposing_abstracts.csv', index=False)
    print("Saved abstracts to drug_repurposing_abstracts.csv\n")

    candidates_raw = await extract_drug_candidates(df)

    all_candidates = []
    for result in candidates_raw:
        if result.lower() != 'none':
            drugs = [d.strip() for d in result.split(',')]
            all_candidates.extend(drugs)

    drug_counts = Counter(all_candidates)
    top_candidates = drug_counts.most_common(10)

    print("\nDRUG REPURPOSING CANDIDATES\n")
    print("Top 10 Candidates:")
    for rank, (drug, count) in enumerate(top_candidates, 1):
        print(f"   {rank}. {drug}: {count} mentions")

    print(f"\nTotal unique candidates: {len(drug_counts)}")
    print(f"API cost: ${session.total_cost():.3f}")

    candidates_df = pd.DataFrame([
        {'drug': drug, 'mentions': count}
        for drug, count in drug_counts.most_common()
    ])
    candidates_df.to_csv('drug_candidates.csv', index=False)
    print("Saved to drug_candidates.csv\n")

    return candidates_df

if __name__ == "__main__":
    try:
        loop = asyncio.get_running_loop()
        import nest_asyncio
        nest_asyncio.apply()
        results = asyncio.run(main())
    except RuntimeError:
        results = asyncio.run(main())





